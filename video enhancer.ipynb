{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "8A1wjeU8t_lI",
    "outputId": "667ca559-2e60-4c66-f58a-bbfb340f57db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: Too many arguments.\n",
      "\n",
      "usage: git clone [<options>] [--] <repo> [<dir>]\n",
      "\n",
      "    -v, --[no-]verbose    be more verbose\n",
      "    -q, --[no-]quiet      be more quiet\n",
      "    --[no-]progress       force progress reporting\n",
      "    --[no-]reject-shallow don't clone shallow repository\n",
      "    -n, --no-checkout     don't create a checkout\n",
      "    --checkout            opposite of --no-checkout\n",
      "    --[no-]bare           create a bare repository\n",
      "    --[no-]mirror         create a mirror repository (implies --bare)\n",
      "    -l, --[no-]local      to clone from a local repository\n",
      "    --no-hardlinks        don't use local hardlinks, always copy\n",
      "    --hardlinks           opposite of --no-hardlinks\n",
      "    -s, --[no-]shared     setup as shared repository\n",
      "    --[no-]recurse-submodules[=<pathspec>]\n",
      "                          initialize submodules in the clone\n",
      "    --[no-]recursive ...  alias of --recurse-submodules\n",
      "    -j, --[no-]jobs <n>   number of submodules cloned in parallel\n",
      "    --[no-]template <template-directory>\n",
      "                          directory from which templates will be used\n",
      "    --[no-]reference <repo>\n",
      "                          reference repository\n",
      "    --[no-]reference-if-able <repo>\n",
      "                          reference repository\n",
      "    --[no-]dissociate     use --reference only while cloning\n",
      "    -o, --[no-]origin <name>\n",
      "                          use <name> instead of 'origin' to track upstream\n",
      "    -b, --[no-]branch <branch>\n",
      "                          checkout <branch> instead of the remote's HEAD\n",
      "    -u, --[no-]upload-pack <path>\n",
      "                          path to git-upload-pack on the remote\n",
      "    --[no-]depth <depth>  create a shallow clone of that depth\n",
      "    --[no-]shallow-since <time>\n",
      "                          create a shallow clone since a specific time\n",
      "    --[no-]shallow-exclude <revision>\n",
      "                          deepen history of shallow clone, excluding rev\n",
      "    --[no-]single-branch  clone only one branch, HEAD or --branch\n",
      "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
      "    --tags                opposite of --no-tags\n",
      "    --[no-]shallow-submodules\n",
      "                          any cloned submodules will be shallow\n",
      "    --[no-]separate-git-dir <gitdir>\n",
      "                          separate git dir from working tree\n",
      "    --[no-]ref-format <format>\n",
      "                          specify the reference format to use\n",
      "    -c, --[no-]config <key=value>\n",
      "                          set config inside the new repository\n",
      "    --[no-]server-option <server-specific>\n",
      "                          option to transmit\n",
      "    -4, --ipv4            use IPv4 addresses only\n",
      "    -6, --ipv6            use IPv6 addresses only\n",
      "    --[no-]filter <args>  object filtering\n",
      "    --[no-]also-filter-submodules\n",
      "                          apply partial clone filters to submodules\n",
      "    --[no-]remote-submodules\n",
      "                          any cloned submodules will use their remote-tracking branch\n",
      "    --[no-]sparse         initialize sparse-checkout file to include only files at root\n",
      "    --[no-]bundle-uri <uri>\n",
      "                          a URI for downloading bundles before fetching from origin remote\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/krasserm/super-resolution.git  #Cloning a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qlrrTdrQuJq4",
    "outputId": "7463366a-18fc-4905-8a0b-f6cb5ad15f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: '/content/super-resolution #Creation of Directory'\n",
      "c:\\Users\\Vicky Singh\\Downloads\\VIDEO-ENHANCEMENT-USING-SINGLE-IMAGE-SUPER-RESOLUTION-master\\VIDEO-ENHANCEMENT-USING-SINGLE-IMAGE-SUPER-RESOLUTION-master\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vicky Singh\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "cd /content/super-resolution #Creation of Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "vLF35wOCuX5a",
    "outputId": "b0e54e4e-8f6b-4645-b91f-ff7f00404085"
   },
   "outputs": [],
   "source": [
    "!tar xvfz /content/weights-srgan.tar.gz #Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mkBU5g7C42BB",
    "outputId": "cbd36a78-e834-44ae-809d-3b6ca3584145"
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries \n",
    "import timeit\n",
    "import cv2 \n",
    "import os\n",
    "import numpy as np\n",
    "from model import resolve_single\n",
    "from utils import load_image, plot_sample\n",
    "from model.srgan import generator\n",
    "\n",
    "# Read the video from specified path \n",
    "cam = cv2.VideoCapture(\"/content/Drama144p_input.3gp\") \n",
    "fps = cam.get(cv2.CAP_PROP_FPS)\n",
    "print(fps)\n",
    "\n",
    "\n",
    "try:\n",
    "      \n",
    "    # Creating a folder named data \n",
    "    if not os.path.exists('data'): \n",
    "        os.makedirs('data') \n",
    "  \n",
    "# if not created then raise error \n",
    "except OSError:\n",
    "    print ('Error: Creating directory of data') \n",
    "  \n",
    "#frames Extraction from video \n",
    "currentframe = 0\n",
    "arr_img = []\n",
    "while(True): \n",
    "      \n",
    "    # reading from frame \n",
    "    ret,frame = cam.read() \n",
    "  \n",
    "    if ret: \n",
    "        # if video is still left continue creating images \n",
    "        name = './data/frame' + str(currentframe).zfill(3) + '.jpg'\n",
    "        print ('Creating...' + name) \n",
    "  \n",
    "        # writing the extracted images \n",
    "        cv2.imwrite(name, frame) \n",
    "  \n",
    "        # increasing counter so that it will show how many frames are created \n",
    "        currentframe += 1\n",
    "        #storing the path of extracted frames in a list\n",
    "        arr_img.append(name)\n",
    "    else: \n",
    "        break\n",
    "#print(arr_img)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "model = generator()\n",
    "model.load_weights('weights/srgan/gan_generator.h5')\n",
    "\n",
    "#Initialization of an empty list to store the super resolved images\n",
    "arr_output=[]\n",
    "print(len(arr_img))\n",
    "n= len(arr_img)\n",
    "\n",
    "#Implementation of SRGAN Model in extracted frames\n",
    "for i in range(n):\n",
    "  lr = load_image(arr_img[i])\n",
    "  sr = resolve_single(model, lr)\n",
    "  #plot_sample(lr, sr)\n",
    "  \n",
    "  arr_output.append(sr)\n",
    "stop = timeit.default_timer()\n",
    "#print(arr_output)\n",
    "\n",
    "print(\"time : \", stop-start)\n",
    "\n",
    "# Release all space and windows once done \n",
    "cam.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62ZtxImOJled"
   },
   "source": [
    "# **Saving the Super Resolved Frames :-**\n",
    "The super resolved frames are in numpy array format, so here we will change them in an image format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHFzAIHUk9N2"
   },
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "#Making a directory for storing super resolved frames in image format\n",
    "os.makedirs(\"output_images\")\n",
    "\n",
    "#Initialization of an empty list to store the path of Super resolved frames\n",
    "s_res= []\n",
    "for j in range(len(arr_output)):\n",
    "  out_name = '/content/super-resolution/output_images/frame' + str(j).zfill(3) + '.jpg'\n",
    "  img_pil = array_to_img(arr_output[j])\n",
    "  img1 = save_img(out_name, img_pil)\n",
    "  s_res.append(out_name)\n",
    "  \n",
    "#print(s_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rAf8BC72W_Yo"
   },
   "source": [
    "# **Conversion of Super Resolved frames into a video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIf9j6qJHU_y"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "for i in range(len(s_res)):\n",
    "    filename=s_res[i]\n",
    "    #reading each files\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "\n",
    "fps = 20       #Put the fps value as your convenience or \n",
    "               #Calculate by using (No. of frames)/Video_duration in seconds  \n",
    "\n",
    "#Creation of output video               \n",
    "out = cv2.VideoWriter('drama2_output.mp4',cv2.VideoWriter_fourcc(*'DIVX'), fps , size)\n",
    "\n",
    "#Writing Frames into video\n",
    "for i in range(len(s_res)):\n",
    "    out.write(cv2.imread(s_res[i]))\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SRGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
